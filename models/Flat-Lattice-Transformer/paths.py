


yangjie_rich_pretrain_unigram_path = '/data2/lx/embeddings/gigaword_chn.all.a2b.uni.ite50.vec'
yangjie_rich_pretrain_bigram_path = '/data2/lx/embeddings/gigaword_chn.all.a2b.bi.ite50.vec'
yangjie_rich_pretrain_word_path = '/data2/lx/embeddings/ctb.50d.vec'
yangjie_rich_pretrain_char_and_word_path = '/data2/lx/embeddings/yangjie_word_char_mix.txt'
# lk_word_path = '/remote-home/xnli/data/pretrain/chinese/sgns.merge.word'
lk_word_path_2 = '/data2/lx/embeddings/sgns.merge.word'



edu_ner_path = '/data2/lx/corpus/EduNER'
ontonote4ner_cn_path = '/remote-home/xnli/data/corpus/sequence_labelling/chinese_ner/OntoNote4NER'
msra_ner_cn_path = '/remote-home/xnli/data/corpus/sequence_labelling/chinese_ner/MSRANER'
resume_ner_path = '/remote-home/xnli/data/corpus/sequence_labelling/chinese_ner/ResumeNER'
weibo_ner_path = '/remote-home/xnli/data/corpus/sequence_labelling/chinese_ner/WeiboNER'



# yangjie_rich_pretrain_unigram_path = '{}/gigaword_chn.all.a2b.uni.ite50.vec'
# yangjie_rich_pretrain_bigram_path = '{}/gigaword_chn.all.a2b.bi.ite50.vec'
# yangjie_rich_pretrain_word_path = '{}/ctb.50d.vec'
#
# # this path is for the output of preprocessing
# yangjie_rich_pretrain_char_and_word_path = '{}/yangjie_word_char_mix.txt'
#
#
#
# ontonote4ner_cn_path = '{}/OntoNote4NER'
# msra_ner_cn_path = '{}/MSRANER'
# resume_ner_path = '{}/ResumeNER'
# weibo_ner_path = '{}/WeiboNER'